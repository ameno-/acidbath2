# SUMMARY

Indie Dev Dan explains three alternatives to MCP servers for connecting agents to external tools while preserving context window: CLI, scripts, and skills approaches.

# IDEAS

- MCP servers consume 10,000 tokens before agents start working, eating 5% of context window immediately
- Multiple MCP servers can burn 20% plus context window before any meaningful work begins
- CLI approach teaches agents to use command-line interfaces instead of consuming MCP server context
- Script-based approach uses progressive disclosure to only load tools when needed, saving massive context
- Skills provide automatic progressive disclosure without requiring prime prompts to activate tool sets
- Context engineering follows prompt engineering; prompts appear before context enters the window for processing
- Agents can manipulate and crud information faster than humans, providing key value proposition
- Prediction markets serve dual purpose as betting platforms and news sites for future information
- Info finance concept uses betting markets to understand incentives before events actually occur
- Single file scripts with UV dependencies eliminate code sharing but improve agent effectiveness
- Progressive disclosure prevents context bloat by conditionally loading only necessary tools and information
- Benchmarks show no quality degradation when using raw code versus MCP servers for tools
- Context preservation becomes critical when stacking multiple large MCP servers in agent workflows
- CLI works for humans, teams, and agents simultaneously, creating powerful interoperability across users
- Building CLI first makes wrapping MCP servers later simple and maintains tool interoperability
- Focused single-purpose agents sidestep context engineering problems by deleting themselves when finished
- Skills represent Claude ecosystem lock-in but provide excellent progressive disclosure for context management
- External tools should use MCP servers 80% of time for simplicity and standards
- New tools should start with CLI approach for maximum flexibility and control
- Script approach trades code duplication for improved agent performance through reduced garbage context
- Progressive disclosure maps conditions to files, creating powerful agentic data structure for context
- Anthropic recommends wrapping MCP functionality in CLI or scripts for better context control
- Tool discovery location and method determines context consumption patterns in agent workflows
- Portability increases from MCP to CLI to scripts to skills approaches respectively
- Engineering investment decreases as simplicity increases across different tool access approaches

# INSIGHTS

- Context window preservation is more critical than tool standardization for high-performance agent workflows
- Progressive disclosure transforms context from liability into strategic asset through conditional loading mechanisms
- Building CLI-first enables seamless scaling from individual use to team collaboration to MCP
- Prompt engineering remains foundational skill that precedes and controls all context engineering efforts
- Agent effectiveness improves dramatically when garbage context is eliminated through targeted tool exposure
- Betting markets provide unique information advantage by revealing future sentiment through financial incentives
- Single-purpose focused agents eliminate most context engineering challenges through deliberate scope limitation
- Tool access trade-offs follow predictable pattern: simplicity versus control across all implementation approaches
- Raw code as tools provides equivalent functionality to MCP with superior context management
- Information finance concept reveals how prediction markets serve as early warning systems
- Context engineering problems often indicate need for better agent architecture rather than solutions
- CLI approach achieves trifecta of human, team, and agent usability without ecosystem lock-in
- Progressive disclosure maps perfectly to agent workflows where tools are conditionally needed
- External versus internal tool development requires fundamentally different optimization strategies and approaches
- Context preservation becomes exponentially important as agent complexity and tool count increases
- Engineering investment should optimize for long-term flexibility rather than short-term implementation ease

# QUOTES

- "Once again, my MCP server just ate 10,000 tokens before my agent even started working." - Indie Dev Dan
- "That's 5% of my agent's context window gone, and my Kshi prediction market MCP server isn't even that large." - Indie Dev Dan
- "Stack up two or three more MCP servers, and I'll be bleeding 20% plus context in no time." - Indie Dev Dan
- "One of the key value propositions of agents is that they can manipulate and crud information on your behalf faster than ever." - Indie Dev Dan
- "The market is telling us with their dollars that by 2029 we expect only a 43% chance that OpenAI achieves whatever AGI is." - Indie Dev Dan
- "OpenAI has to announce that they've achieved AGI. Who knows what AGI is? No one knows anymore." - Indie Dev Dan
- "Use raw code as tools." - Indie Dev Dan
- "Here we're in full control over everything." - Indie Dev Dan
- "Do not read any other Python files." - Indie Dev Dan
- "There's two ways to use these betting markets. It's a betting site for some people and you know for those looking to make high return on investment decisions." - Vitalic Buterin
- "This is also a news site, right? It's a place of finding valuable information." - Vitalic Buterin
- "Vitalic calls this info finance." - Indie Dev Dan
- "You can use these betting platforms to understand incentives before things happen." - Indie Dev Dan
- "What if you don't need MCP at all?" - Mario
- "Even before context comes prompt engineering. This is still a critical skill." - Indie Dev Dan
- "In fact, it is the critical skill for engineers in 2025 and beyond." - Indie Dev Dan
- "The prompt shows up before the context gets in your context window." - Indie Dev Dan
- "We have just prompt engineered out 10,000 tokens that don't show up via a default MCP server." - Indie Dev Dan
- "When you have less garbage context, your agent can perform better." - Indie Dev Dan
- "Benchmarks have shown that there's no degradation in quality by going right for scripts, going right for CLI." - Mario
- "Don't give away your understanding of how to write great prompts because at the end of the day, everything is just the core for context, model, prompt, and tools." - Indie Dev Dan
- "Everything is just the core for context, model, prompt, and tools." - Indie Dev Dan
- "Everything has trade-offs, right? It's not just that we want to go beyond MCP and that MCP is bad." - Indie Dev Dan
- "There's no one winner takes all approach. There are options and tradeoffs." - Indie Dev Dan
- "You can sidestep every single context engineering problem by just focusing your agents on one problem and then you delete them when they're done." - Indie Dev Dan
- "CLI works for you, works for your team, and your agents understand it as well." - Indie Dev Dan
- "I am always aware of lock in and skills is a claude specific lockin mechanism." - Indie Dev Dan
- "CLI gets you all three out of the box." - Indie Dev Dan
- "Stay focused and keep building." - Indie Dev Dan

# HABITS

- Always check context window consumption with /context command before starting agent work sessions
- Prime agents with specific prompts before activating tool sets to control context consumption
- Use single-purpose focused agents that delete themselves when tasks are completed successfully
- Build CLI interfaces first before wrapping them in MCP servers for maximum flexibility
- Read readme and CLI files only when priming agents to understand tool capabilities
- Use UV dependency manager for single file scripts with dependencies declared at top
- Prompt engineer progressive disclosure to prevent unnecessary context window consumption from tools
- Start with external MCP servers 80% of time for simplicity in tool integration
- Switch to CLI approach 15% of time when needing specific control over tools
- Use scripts or skills 5% of time only when context preservation becomes critical
- Always build for trifecta of human, team, and agent usability when creating tools
- Check tool descriptions and help documentation before reading full script implementations
- Map conditions to files for creating powerful agentic data structures in workflows
- Use prediction markets as information source rather than just betting platforms for insights
- Implement progressive disclosure by teaching agents when to use each script conditionally

# FACTS

- MCP servers can consume 10,000 tokens before agents begin actual work on tasks
- Multiple MCP servers can consume over 20% of agent context windows immediately
- Haiku model provides sufficient capability for prediction market analysis without requiring Sonnet
- UV Python dependency manager allows single file scripts with dependencies declared at top
- Anthropic recommends progressive disclosure and direct tool calls over standard MCP approaches
- Benchmarks show no quality degradation using raw code versus MCP servers for tools
- CLI approach can save roughly 4% context window compared to MCP server implementations
- Script-based approach can reduce context consumption to 10% of original MCP usage
- Skills provide automatic progressive disclosure without requiring manual prime prompts for activation
- Prediction markets serve as both betting platforms and news sites for future information
- Elon Musk currently has reported net worth of 500 billion dollars according to markets
- Sam Altman currently has reported net worth of 2 billion dollars significantly lower
- Jensen Huang has approximately 175 billion dollar net worth based on current valuations
- Government shutdown prediction markets show 66-63% probability for specific duration ranges
- OpenAI AGI achievement markets show only 43% probability by 2030 according to bettors

# REFERENCES

- Koshi prediction markets betting platform for accessing market sentiment and future predictions
- Anthropic blog on using direct tool calls and progressive disclosure for better context
- Mario's engineering approach arguing against need for MCP servers in agent workflows
- Vitalik Buterin's concept of info finance for understanding prediction markets as information
- Astral UV Python dependency manager for single file scripts with declared dependencies
- Claude Code ecosystem and skills functionality for agent tool management and discovery
- Tactical Agent Coding course covering focused single-purpose agent architecture and implementation patterns
- Polymarket and Kalshi platforms for prediction market data and sentiment analysis
- Beyond MCP server codebase demonstrating all three alternative approaches to tool access
- Click and Typer CLI frameworks for building command-line interfaces agents can understand
- OpenAI AGI achievement prediction market for understanding AI development timeline sentiment
- Government shutdown duration betting markets for political event timeline prediction analysis
- Trillionaire prediction markets for understanding wealth accumulation timeline expectations and sentiment
- Best AI model end-of-year prediction markets for technology development and benchmark analysis

# ONE-SENTENCE TAKEAWAY

Build CLI-first tools with progressive disclosure to preserve agent context while maintaining control.

# RECOMMENDATIONS

- Use MCP servers 80% of time for external tools to leverage existing standards
- Switch to CLI approach when you need specific control over tool behavior and context
- Implement script-based approach only when context preservation becomes absolutely critical for agent performance
- Prime agents with specific prompts before activating tool sets to control context consumption effectively
- Build single-purpose focused agents that delete themselves when tasks complete to sidestep context issues
- Start with CLI development before wrapping MCP servers to maintain interoperability across different approaches
- Use UV dependency manager for single file scripts to eliminate dependency management complexity
- Implement progressive disclosure by mapping conditions to files for powerful agentic data structures
- Teach agents when to use each script conditionally rather than loading all tools
- Check context window consumption regularly with /context command during agent workflow development sessions
- Use prediction markets as information sources for understanding future sentiment through financial incentives
- Build for trifecta of human, team, and agent usability when creating new tools
- Prompt engineer progressive disclosure outcomes rather than relying solely on context engineering approaches
- Read tool documentation and help files before consuming full script implementations in workflows
- Maintain awareness of ecosystem lock-in when choosing between different tool access approaches
- Use Haiku model for prediction market analysis as Sonnet provides unnecessary overhead for tasks
- Implement CLI interfaces that work equally well for humans, teams, and agents simultaneously
- Focus on prompt engineering as foundational skill that precedes all context engineering efforts
- Trade code duplication for improved agent performance when context preservation becomes critical priority
- Use betting markets to understand incentives and future events before they actually occur
